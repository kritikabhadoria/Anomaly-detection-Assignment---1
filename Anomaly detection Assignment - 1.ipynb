{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf9c8856-1f66-432f-a8ad-7665d3100198",
   "metadata": {},
   "source": [
    "### Q1. What is anomaly detection and what is its purpose?\n",
    "\n",
    "Anomaly detection is the process of identifying data points, observations, or patterns in a dataset that deviate significantly from the norm or expected behavior. These deviations, also known as anomalies, outliers, or exceptions, can indicate critical and actionable information. The purpose of anomaly detection is to identify these rare events or observations which can be indicative of significant but rare events such as fraud, network intrusions, equipment failures, or other unusual activities that require attention.\n",
    "\n",
    "### Q2. What are the key challenges in anomaly detection?\n",
    "\n",
    "1. **Imbalanced Data**: Anomalies are rare compared to normal instances, making it challenging to train models effectively.\n",
    "2. **High Dimensionality**: As the number of features increases, it becomes harder to detect anomalies due to the curse of dimensionality.\n",
    "3. **Varied Anomaly Types**: Anomalies can be point anomalies, contextual anomalies, or collective anomalies, requiring different detection approaches.\n",
    "4. **Dynamic Environments**: Anomalies and normal behavior can change over time, necessitating adaptive methods.\n",
    "5. **Label Scarcity**: Labeled anomalies are often scarce, making supervised learning difficult.\n",
    "6. **Noise**: Real-world data often contains noise that can be mistaken for anomalies.\n",
    "7. **Interpretability**: Understanding why a point is classified as an anomaly can be challenging, yet it's crucial for actionable insights.\n",
    "\n",
    "### Q3. How does unsupervised anomaly detection differ from supervised anomaly detection?\n",
    "\n",
    "- **Unsupervised Anomaly Detection**: This approach does not require labeled data. It assumes that anomalies are rare and different from the normal data. Algorithms identify anomalies based on inherent data characteristics, such as clustering or density. Examples include Isolation Forest, k-means clustering, and DBSCAN.\n",
    "\n",
    "- **Supervised Anomaly Detection**: This method uses labeled datasets where normal and anomalous instances are pre-identified. Models are trained to distinguish between these two classes. Techniques include classification algorithms like SVM, neural networks, and logistic regression.\n",
    "\n",
    "### Q4. What are the main categories of anomaly detection algorithms?\n",
    "\n",
    "1. **Statistical Methods**: These assume a distribution for the data and identify anomalies based on statistical properties. Examples include z-score and Gaussian models.\n",
    "2. **Proximity-Based Methods**: These detect anomalies based on the distance or density of data points. Examples are k-nearest neighbors (KNN), Local Outlier Factor (LOF), and DBSCAN.\n",
    "3. **Clustering-Based Methods**: These identify anomalies as data points that do not fit well into any cluster. Examples include k-means and hierarchical clustering.\n",
    "4. **Classification-Based Methods**: These use labeled data to classify points as normal or anomalous. Examples include SVM and neural networks.\n",
    "5. **Reconstruction-Based Methods**: These involve reconstructing the data and identifying points that have high reconstruction errors. Examples include autoencoders and PCA.\n",
    "6. **Ensemble Methods**: These combine multiple algorithms to improve detection performance. Examples include Isolation Forest and ensembles of various classifiers.\n",
    "\n",
    "### Q5. What are the main assumptions made by distance-based anomaly detection methods?\n",
    "\n",
    "1. **Anomalies are distant**: Anomalies are far from the majority of the data points.\n",
    "2. **Homogeneous Density**: Normal data points are assumed to be in dense regions, while anomalies are in sparse regions.\n",
    "3. **Fixed Distance Threshold**: A predefined distance or density threshold is often used to distinguish between normal and anomalous points.\n",
    "\n",
    "### Q6. How does the LOF algorithm compute anomaly scores?\n",
    "\n",
    "The Local Outlier Factor (LOF) algorithm computes anomaly scores based on the local density deviation of a data point compared to its neighbors. Here's the process:\n",
    "\n",
    "1. **Calculate k-distance**: For a point, compute the distance to its k-th nearest neighbor.\n",
    "2. **Reachability distance**: Define the reachability distance of a point A from point B as the maximum of the k-distance of B and the actual distance between A and B.\n",
    "3. **Local reachability density (LRD)**: For a point, calculate the inverse of the average reachability distance to all its k-nearest neighbors.\n",
    "4. **LOF score**: The LOF score for a point is the average of the ratios of the LRDs of its k-nearest neighbors to its own LRD. A higher LOF score indicates a higher likelihood of being an anomaly.\n",
    "\n",
    "### Q7. What are the key parameters of the Isolation Forest algorithm?\n",
    "\n",
    "1. **Number of Trees (n_estimators)**: The number of isolation trees to build. More trees can improve accuracy but increase computation time.\n",
    "2. **Subsampling Size (max_samples)**: The number of data points used to build each tree. A smaller subset size reduces computation and improves detection of anomalies.\n",
    "3. **Contamination (optional)**: The expected proportion of anomalies in the dataset, used to define the threshold for anomaly scores.\n",
    "\n",
    "### Q8. If a data point has only 2 neighbours of the same class within a radius of 0.5, what is its anomaly score using KNN with K=10?\n",
    "\n",
    "In k-nearest neighbors (KNN) anomaly detection, a data point's anomaly score is typically determined based on the distance to its k-th nearest neighbor. However, if the context is a classification task, and the data point has only 2 neighbors of the same class within a radius of 0.5 when K=10, this implies that the remaining 8 neighbors are of different classes or further away. This could be interpreted as:\n",
    "\n",
    "- **High Anomaly Score**: Since the point has few similar neighbors within the specified distance, it is likely considered an anomaly because it doesn't fit well within its local neighborhood.\n",
    "\n",
    "### Q9. Using the Isolation Forest algorithm with 100 trees and a dataset of 3000 data points, what is the anomaly score for a data point that has an average path length of 5.0 compared to the average path length of the trees?\n",
    "\n",
    "In Isolation Forest, the anomaly score is based on the average path length of a data point compared to the expected path length for an isolation tree. For a dataset of size \\(n\\), the average path length \\(c(n)\\) is given by:\n",
    "\n",
    "\\[ c(n) = 2H(n-1) - \\frac{2(n-1)}{n} \\]\n",
    "\n",
    "where \\(H(n)\\) is the harmonic number, approximated by \\(H(n) \\approx \\ln(n) + \\gamma\\) (Euler's constant \\(\\gamma \\approx 0.577\\)).\n",
    "\n",
    "For \\(n = 3000\\):\n",
    "\n",
    "\\[ H(2999) \\approx \\ln(2999) + 0.577 \\approx 8.006 \\]\n",
    "\\[ c(3000) \\approx 2 \\times 8.006 - \\frac{2 \\times 2999}{3000} \\approx 16.012 - 1.998 \\approx 14.014 \\]\n",
    "\n",
    "Given the data point's average path length is 5.0, we can calculate the anomaly score \\(s\\):\n",
    "\n",
    "\\[ s = 2^{-\\frac{E(h(x))}{c(n)}} \\]\n",
    "\\[ s = 2^{-\\frac{5.0}{14.014}} \\approx 2^{-0.357} \\approx 0.77 \\]\n",
    "\n",
    "Thus, the anomaly score for the data point is approximately 0.77. A score closer to 1 indicates a higher likelihood of being an anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c247370f-7f2d-420b-a246-d17ebd602b69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
